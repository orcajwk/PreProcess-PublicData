{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob(\"./data/raw_data/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    encodings = [\"utf-8\", \"cp949\"]\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, low_memory=False, encoding=encoding)\n",
    "            return (df, encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except pd.errors.ParserError:\n",
    "            return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_encoding_dict = dict()\n",
    "file_column_dict = dict()\n",
    "\n",
    "for file_path in tqdm(file_paths):\n",
    "    df, encoding = read_csv(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        file_encoding_dict[file_path] = encoding\n",
    "        file_column_dict[file_path] = list(df.columns)\n",
    "    \n",
    "    else:\n",
    "        file_encoding_dict[file_path] = \"ParseError\"\n",
    "        file_column_dict[file_path] = \"ParseError\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(list(file_encoding_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = lambda file_path: pd.read_csv(file_path, low_memory=False, encoding='cp949')\n",
    "with open(\"./read_csv.pkl\", 'wb') as f:\n",
    "    dill.dump(read_csv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = list(file_column_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(sum(columns_list,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_first = lambda x: x.split()[0]\n",
    "\n",
    "preproc = lambda cols: [get_first(col) for col in cols]\n",
    "Counter(sum(list(map(preproc,columns_list)),[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_first = lambda x: x.split()[0]\n",
    "do_strip = lambda x: x.strip()\n",
    "\n",
    "preproc = lambda cols: [do_strip(get_first(col)) for col in cols]\n",
    "Counter(sum(list(map(preproc,columns_list)),[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_first = lambda x: x.split()[0]\n",
    "do_strip = lambda x: x.strip()\n",
    "drop_bracket = lambda x : x.split(\"(\")[0]\n",
    "\n",
    "preproc = lambda cols: [drop_bracket(do_strip(get_first(col))) for col in cols]\n",
    "Counter(sum(list(map(preproc,columns_list)),[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composer(*funcs):\n",
    "    return reduce(lambda f, g: lambda x: g(f(x)), funcs)\n",
    "\n",
    "\n",
    "def get_first(x):\n",
    "    return x.split()[0]\n",
    "\n",
    "\n",
    "def do_strip(x):\n",
    "    return x.strip()\n",
    "\n",
    "\n",
    "def drop_bracket(x):\n",
    "    return x.split(\"(\")[0]\n",
    "\n",
    "preproc = composer(get_first, do_strip, drop_bracket)\n",
    "# Counter(sum(list(map(preproc,columns_list)),[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open(\"./preproc_column.pkl\", 'wb') as f:\n",
    "    dill.dump(preproc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    # base_cols\n",
    "    '자료생성년월': 100,\n",
    "    '사업자등록번호': 100,\n",
    "    # corp_cols\n",
    "    '사업장명': 100,\n",
    "    '사업장가입상태코드': 100,\n",
    "    '사업장형태구분코드': 100,\n",
    "    '사업장업종코드': 100,\n",
    "    '사업장업종코드명': 100,\n",
    "    '적용일자': 100,\n",
    "    '재등록일자': 100,\n",
    "    '탈퇴일자': 100,\n",
    "    # addr_cols\n",
    "    '사업장지번상세주소': 100,\n",
    "    '사업장도로명상세주소': 100,\n",
    "    '고객법정동주소코드': 100,\n",
    "    '고객행정동주소코드': 100,\n",
    "    '법정동주소광역시도코드': 100,\n",
    "    '법정동주소광역시시군구코드': 100,\n",
    "    '법정동주소광역시시군구읍면동코드': 100,\n",
    "    '우편번호': 100,\n",
    "    # nps_cols (national pension service(국민연금))\n",
    "    '가입자수': 100,\n",
    "    '당월고지금액': 100,\n",
    "    '신규취득자수': 100,\n",
    "    '상실가입자수': 100,\n",
    "}\n",
    "\n",
    "with open(\"./columns.pkl\", 'wb') as f:\n",
    "    dill.dump(columns, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
